{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOARe4JGHBPd2GF4qQf0IPX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanadv/SkinCancerClassificationModels/blob/main/Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyH67GATomdU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (Layer, Input, Lambda, Conv2D, MaxPooling2D, Conv2DTranspose,\n",
        "                                     BatchNormalization, LeakyReLU, Dropout, concatenate,\n",
        "                                     Average, Resizing, multiply, Flatten, Dense)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import MultiHeadAttention\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Concatenate, Average, GlobalAveragePooling2D, Dense, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#from vit_keras import vit\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2D, LeakyReLU, MaxPooling2D\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, LeakyReLU, concatenate, Dropout, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.layers import multiply\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.layers import Resizing\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Lambda, Average\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import GaussianNoise\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.applications import EfficientNetB0, MobileNetV2, ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, concatenate, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten,Lambda\n",
        "from tensorflow.keras.layers import Average, Lambda, Conv2D, Resizing, UpSampling2D, MaxPooling2D\n",
        "import time\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "from tensorflow.keras.layers import Dense, Dropout, Concatenate, Flatten,Reshape\n",
        "\n",
        "# Define the ensemble model creation function\n",
        "from tensorflow.keras.layers import Conv2D, LayerNormalization, MultiHeadAttention\n",
        "\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications import Xception, InceptionV3, NASNetMobile\n",
        "from tensorflow.keras.layers import DepthwiseConv2D, Add, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten,BatchNormalization,Activation\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from vit_keras import vit\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply,ReLU\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, Add, Reshape, multiply\n",
        "from keras.regularizers import l2\n",
        "from keras.models import Model\n",
        "from keras.layers import Layer, MultiHeadAttention\n",
        "\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Reshape, Multiply\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "extract_path = '/content/drive/MyDrive/hamdataset'\n",
        "\n",
        "# Parameters\n",
        "batch_size = 8\n",
        "epochs = 50\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# Define the input 3 and batch size\n",
        "input_shape = (128, 128, 3)  # 128x128 with RGB images (3 channels)\n",
        "\n",
        "# Initialize the ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Training data generator\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    extract_path,  # Replace with your directory path\n",
        "    target_size=input_shape[:2],  # Resize images to 128x128\n",
        "    color_mode='rgb',  # Set color mode to RGB\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training')\n",
        "\n",
        "# Validation data generator\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    extract_path,  # Replace with your directory path\n",
        "    target_size=input_shape[:2],  # Resize images to 128x128\n",
        "    color_mode='rgb',  # Set color mode to RGB\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')\n",
        "\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Multiply\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def squeeze_excite_block(input, ratio=8):\n",
        "    init = input\n",
        "    channel_axis = -1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling2D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu')(se)\n",
        "    se = Dense(filters, activation='sigmoid')(se)\n",
        "\n",
        "    x = multiply([init, se])\n",
        "    return x\n",
        "\n",
        "class SelfAttentionLayer(Layer):\n",
        "    def __init__(self, embed_dim=32, num_heads=2, **kwargs):\n",
        "        super(SelfAttentionLayer, self).__init__(**kwargs)\n",
        "        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.attention(inputs, inputs)\n",
        "\n",
        "def depthwise_separable_conv_block(inputs, num_filters, kernel_size=3, padding='same'):\n",
        "    x = DepthwiseConv2D(kernel_size=kernel_size, padding=padding)(inputs)\n",
        "    x = Conv2D(num_filters, kernel_size=1, padding=padding)(x)\n",
        "    return x\n",
        "\n",
        "def build_vit_model_with_transfer_learningOP2(input_shape, num_classes=3):\n",
        "    input_layer = Input(input_shape)\n",
        "\n",
        "    def edge_detection_layer(x):\n",
        "        sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)\n",
        "        sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float32)\n",
        "        sobel_x = np.expand_dims(sobel_x, axis=-1)\n",
        "        sobel_x = np.repeat(sobel_x, 3, axis=-1)\n",
        "        sobel_x = np.expand_dims(sobel_x, axis=-1)\n",
        "        sobel_y = np.expand_dims(sobel_y, axis=-1)\n",
        "        sobel_y = np.repeat(sobel_y, 3, axis=-1)\n",
        "        sobel_y = np.expand_dims(sobel_y, axis=-1)\n",
        "        sobel_x = tf.convert_to_tensor(sobel_x)\n",
        "        sobel_y = tf.convert_to_tensor(sobel_y)\n",
        "        sobel_x = tf.nn.depthwise_conv2d(x, sobel_x, strides=[1, 1, 1, 1], padding='SAME')\n",
        "        sobel_y = tf.nn.depthwise_conv2d(x, sobel_y, strides=[1, 1, 1, 1], padding='SAME')\n",
        "        edges = tf.math.abs(sobel_x) + tf.math.abs(sobel_y)\n",
        "        return edges\n",
        "\n",
        "    def orientation_pooling(inputs):\n",
        "        rotations = [0, 90, 180, 270]\n",
        "        outputs = []\n",
        "        for angle in rotations:\n",
        "            rotated = Lambda(lambda x: tf.image.rot90(x, k=angle // 90))(inputs)\n",
        "            outputs.append(rotated)\n",
        "        return Average()(outputs)\n",
        "\n",
        "    edges = Lambda(edge_detection_layer)(input_layer)\n",
        "\n",
        "    # U-Net with reduced filters\n",
        "    c1 = depthwise_separable_conv_block(input_layer, 32)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = depthwise_separable_conv_block(c1, 32)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = depthwise_separable_conv_block(p1, 64)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = depthwise_separable_conv_block(c2, 64)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = depthwise_separable_conv_block(p2, 128)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = depthwise_separable_conv_block(c3, 128)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = depthwise_separable_conv_block(p3, 256)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = depthwise_separable_conv_block(c4, 256)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    c5 = depthwise_separable_conv_block(p4, 512)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = depthwise_separable_conv_block(c5, 512)\n",
        "\n",
        "    u6 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = depthwise_separable_conv_block(u6, 256)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = depthwise_separable_conv_block(c6, 256)\n",
        "\n",
        "    u7 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = depthwise_separable_conv_block(u7, 128)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = depthwise_separable_conv_block(c7, 128)\n",
        "\n",
        "    u8 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = depthwise_separable_conv_block(u8, 64)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = depthwise_separable_conv_block(c8, 64)\n",
        "\n",
        "    u9 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    c9 = depthwise_separable_conv_block(u9, 32)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = depthwise_separable_conv_block(c9, 32)\n",
        "\n",
        "    x = orientation_pooling(c9)\n",
        "    x = Conv2D(3, (1, 1), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "        # Continue from Dropout\n",
        "    x = Dropout(0.4)(x)\n",
        "    target_height, target_width = x.shape[1], x.shape[2]\n",
        "    resized_edges = Resizing(target_height, target_width)(edges)\n",
        "\n",
        "    # Concatenate x and resized edges\n",
        "    x = concatenate([x, resized_edges])\n",
        "    x = orientation_pooling(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = squeeze_excite_block(x)\n",
        "    x = SelfAttentionLayer(embed_dim=32, num_heads=2)(x)\n",
        "    x = Conv2D(3, (1, 1), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
        "\n",
        "\n",
        "    vit_model = vit.vit_b32(\n",
        "        image_size=input_shape[0],\n",
        "        activation='softmax',\n",
        "        pretrained=True,\n",
        "        include_top=True,\n",
        "        pretrained_top=False,\n",
        "        classes=num_classes\n",
        "    )(x)\n",
        "\n",
        "    return Model(inputs=input_layer, outputs=vit_model)\n",
        "\n",
        "\n",
        "\n",
        "def squeeze_excite_block(input, ratio=16):\n",
        "    init = input\n",
        "    channel_axis = -1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling2D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "\n",
        "    x = Multiply()([init, se])\n",
        "    return x\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        " # Normalization\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    print(\"Shape after LayerNormalization:\", x.shape)  # Debugging print\n",
        "\n",
        "    # Expanding the dimensions to add sequence length\n",
        "    x = tf.expand_dims(x, axis=1)\n",
        "    print(\"Shape after expanding dimensions:\", x.shape)  # Debugging print\n",
        "\n",
        "    # Apply MultiHeadAttention\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
        "    print(\"Shape after MultiHeadAttention:\", x.shape)  # Debugging print\n",
        "\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Dense(inputs.shape[-1])(x)\n",
        "    return x + res\n",
        "\n",
        "def build_cnn_with_attention(input_shape, num_classes, embed_dim=32, num_heads=2, num_transformer_layers=2, ff_dim=32):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # DenseNet121 for Feature Extraction\n",
        "    densenet = DenseNet121(include_top=False, input_tensor=inputs, weights='imagenet')\n",
        "    densenet.trainable = False\n",
        "\n",
        "    # Custom layers onto densenet\n",
        "    x = densenet.output\n",
        "    x = Conv2D(16, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = squeeze_excite_block(x)\n",
        "\n",
        "    x = Conv2D(16, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = squeeze_excite_block(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    # Flatten and apply Transformer blocks\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(embed_dim)(x)  # Projecting to transformer dimension\n",
        "\n",
        "    for _ in range(num_transformer_layers):\n",
        "        x = transformer_encoder(x, embed_dim, num_heads, ff_dim)\n",
        "\n",
        "    # Classifier head\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "\n",
        "    print(\"Shape before softmax:\", x.shape)  # Add this line for debugging\n",
        "\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
        "\n",
        "\n",
        "def build_densnet(input_shape, num_classes,embed_dim=32):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # DenseNet121 for Feature Extraction\n",
        "    densenet = DenseNet121(include_top=False, input_tensor=inputs, weights='imagenet')\n",
        "    densenet.trainable = False\n",
        "\n",
        "    # Custom layers onto densenet\n",
        "    x = densenet.output\n",
        "\n",
        "    # Adding layers to process the output into a suitable form for classification\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(embed_dim, activation='relu')(x)  # Embedding layer (optional, can adjust the size)\n",
        "    x = Dense(num_classes, activation='softmax')(x)  # Output layer for classification\n",
        "\n",
        "    model = Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "def build_efficientnet_model(input_shape, num_classes):\n",
        "    # Load the pre-trained EfficientNetB0 model without the top layer\n",
        "    base_model = EfficientNetB0(include_top=False, input_shape=input_shape, weights='imagenet')\n",
        "\n",
        "    # Freeze the base_model\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Create the input layer\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Use the EfficientNetB0 model as the base\n",
        "    x = base_model(inputs, training=False)  # Make sure the base model is running in inference mode here\n",
        "\n",
        "    # Add GlobalAveragePooling2D layer to reduce feature maps size\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Add a Dense layer with a softmax activation for the classification\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Construct the final model\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    return model\n",
        "def build_vit_model(input_shape, num_classes):\n",
        "    input_layer = Input(input_shape)\n",
        "    vit_model = vit.vit_b32(\n",
        "        image_size=input_shape[0],\n",
        "        activation='softmax',\n",
        "        pretrained=True,\n",
        "        include_top=True,\n",
        "        pretrained_top=False,\n",
        "        classes=num_classes\n",
        "    )(input_layer)\n",
        "\n",
        "    return Model(inputs=input_layer, outputs=vit_model)\n",
        "\n",
        "def build_mobilenet_model(input_shape, num_classes=3):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # Use MobileNetV2 directly on the input_layer\n",
        "    mobilenet_model = tf.keras.applications.MobileNetV2(input_shape=input_shape[:2] + (3,), include_top=False)(input_layer)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(mobilenet_model)\n",
        "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "def build_resnet_model(input_shape, num_classes=3):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    resnet_model = tf.keras.applications.ResNet50(input_shape=input_shape[:2] + (3,), include_top=False)(input_layer)\n",
        "    x = GlobalAveragePooling2D()(resnet_model)\n",
        "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
        "    return Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "\n",
        "def build_unet_model(input_shape,num_classes):\n",
        "    unet_input = Input(shape=input_shape)\n",
        "\n",
        "    # Contracting Path\n",
        "    c1 = Conv2D(32, (3,3), padding='same', activation='relu')(unet_input)\n",
        "    p1 = MaxPooling2D((2,2))(c1)\n",
        "    c2 = Conv2D(64, (3,3), padding='same', activation='relu')(p1)\n",
        "    p2 = MaxPooling2D((2,2))(c2)\n",
        "    c3 = Conv2D(128, (3,3), padding='same', activation='relu')(p2)\n",
        "    p3 = MaxPooling2D((2,2))(c3)\n",
        "    c4 = Conv2D(256, (3,3), padding='same', activation='relu')(p3)\n",
        "\n",
        "    # Expansive Path\n",
        "    u1 = UpSampling2D((2,2))(c4)\n",
        "    m1 = concatenate([u1, c3])\n",
        "    c5 = Conv2D(128, (3,3), padding='same', activation='relu')(m1)\n",
        "    u2 = UpSampling2D((2,2))(c5)\n",
        "    m2 = concatenate([u2, c2])\n",
        "    c6 = Conv2D(64, (3,3), padding='same', activation='relu')(m2)\n",
        "    u3 = UpSampling2D((2,2))(c6)\n",
        "    m3 = concatenate([u3, c1])\n",
        "    c7 = Conv2D(32, (3,3), padding='same', activation='relu')(m3)\n",
        "\n",
        "    # Final Layers\n",
        "    gap = GlobalAveragePooling2D()(c7)\n",
        "    unet_output = Dense(num_classes, activation='softmax')(gap)\n",
        "\n",
        "    return Model(unet_input, unet_output)\n",
        "\n",
        "# ... [previous imports remain unchanged]\n",
        "\n",
        "def build_darknet_model(input_shape, num_classes):\n",
        "    # Simplified DarkNet-19 model\n",
        "    def conv_block(x, filters, kernel_size, strides=(1, 1), max_pool=True):\n",
        "        x = Conv2D(filters, kernel_size, strides=strides, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "        if max_pool:\n",
        "            x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
        "        return x\n",
        "\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    x = conv_block(input_layer, 32, (3, 3))\n",
        "    x = conv_block(x, 64, (3, 3))\n",
        "    x = conv_block(x, 128, (3, 3), max_pool=False)\n",
        "    x = conv_block(x, 64, (1, 1), max_pool=False)\n",
        "    x = conv_block(x, 128, (3, 3))\n",
        "    x = conv_block(x, 256, (3, 3), max_pool=False)\n",
        "    x = conv_block(x, 128, (1, 1), max_pool=False)\n",
        "    x = conv_block(x, 256, (3, 3))\n",
        "    x = conv_block(x, 512, (3, 3), max_pool=False)\n",
        "    x = conv_block(x, 256, (1, 1), max_pool=False)\n",
        "    x = conv_block(x, 512, (3, 3), max_pool=False)\n",
        "    x = conv_block(x, 256, (1, 1), max_pool=False)\n",
        "    x = conv_block(x, 512, (3, 3))\n",
        "    x = conv_block(x, 1024, (3, 3), max_pool=False)\n",
        "    x = conv_block(x, 512, (1, 1), max_pool=False)\n",
        "    x = conv_block(x, 1024, (3, 3), max_pool=False)\n",
        "    x = conv_block(x, 512, (1, 1), max_pool=False)\n",
        "    x = conv_block(x, 1024, (3, 3))\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
        "    f_name = \"fire\" + str(fire_id) + \"/\"\n",
        "\n",
        "    # Squeeze layer\n",
        "    x = Conv2D(squeeze, (1, 1), padding='valid', name=f_name + \"squeeze1x1\")(x)\n",
        "    x = Activation('relu', name=f_name + \"squeeze1x1_activation\")(x)\n",
        "\n",
        "    # Expand layer 1x1\n",
        "    left = Conv2D(expand, (1, 1), padding='valid', name=f_name + \"expand1x1\")(x)\n",
        "    left = Activation('relu', name=f_name + \"expand1x1_activation\")(left)\n",
        "\n",
        "    # Expand layer 3x3\n",
        "    right = Conv2D(expand, (3, 3), padding='same', name=f_name + \"expand3x3\")(x)\n",
        "    right = Activation('relu', name=f_name + \"expand3x3_activation\")(right)\n",
        "\n",
        "    # Concatenate expand layers\n",
        "    x = concatenate([left, right], axis=3, name=f_name + \"concat\")\n",
        "    return x\n",
        "\n",
        "def build_squeezenet_model(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Initial convolution layer\n",
        "    x = Conv2D(64, (3, 3), strides=(2, 2), padding='same', name='conv1')(inputs)\n",
        "    x = Activation('relu', name='conv1_activation')(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool1')(x)\n",
        "\n",
        "    # Fire modules\n",
        "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
        "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool2')(x)\n",
        "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
        "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool3')(x)\n",
        "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
        "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
        "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
        "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
        "\n",
        "    # Final layers\n",
        "    x = Dropout(0.5, name='drop9')(x)\n",
        "    x = Conv2D(num_classes, (1, 1), padding='valid', name='conv10')(x)\n",
        "    x = Activation('relu', name='conv10_activation')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Activation('softmax', name='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs=x)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def squeeze_excite_block(input, ratio=16):\n",
        "    init = input\n",
        "    channel_axis = -1  # assuming channels last format\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling2D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu')(se)\n",
        "    se = Dense(filters, activation='sigmoid')(se)\n",
        "\n",
        "    x = multiply([init, se])\n",
        "    return x\n",
        "class SelfAttentionLayer(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, **kwargs):\n",
        "        super(SelfAttentionLayer, self).__init__(**kwargs)\n",
        "        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Self attention\n",
        "        return self.attention(inputs, inputs)\n",
        "\n",
        "def build_cnn_with_attentionNodens(input_shape, num_classes, embed_dim=32, num_heads=2):\n",
        "    input_layer = Input(input_shape)\n",
        "\n",
        "    # Layer 1\n",
        "    x = Conv2D(16, (3, 3), padding='same')(input_layer)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = squeeze_excite_block(x)\n",
        "\n",
        "    # Layer 2\n",
        "    x = Conv2D(16, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = SelfAttentionLayer(embed_dim, num_heads)(x)\n",
        "\n",
        "    # Layer 3\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = squeeze_excite_block(x)\n",
        "\n",
        "    # Layer 4\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Layer 5\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = SelfAttentionLayer(embed_dim, num_heads)(x)\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output)\n",
        "    return model\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, Multiply\n",
        "import tensorflow as tf\n",
        "\n",
        "def ChannelAttentionModule(input_feature, ratio=8):\n",
        "    channel = input_feature.shape[-1]\n",
        "    shared_layer_one = Dense(channel//ratio,\n",
        "                             activation='relu',\n",
        "                             kernel_initializer='he_normal',\n",
        "                             use_bias=True,\n",
        "                             bias_initializer='zeros')\n",
        "    shared_layer_two = Dense(channel,\n",
        "                             kernel_initializer='he_normal',\n",
        "                             use_bias=True,\n",
        "                             bias_initializer='zeros')\n",
        "\n",
        "    avg_pool = GlobalAveragePooling2D()(input_feature)\n",
        "    avg_pool = Reshape((1, 1, channel))(avg_pool)\n",
        "    avg_pool = shared_layer_one(avg_pool)\n",
        "    avg_pool = shared_layer_two(avg_pool)\n",
        "\n",
        "    max_pool = tf.keras.layers.GlobalMaxPooling2D()(input_feature)\n",
        "    max_pool = Reshape((1, 1, channel))(max_pool)\n",
        "    max_pool = shared_layer_one(max_pool)\n",
        "    max_pool = shared_layer_two(max_pool)\n",
        "\n",
        "    cbam_feature = tf.keras.layers.Add()([avg_pool, max_pool])\n",
        "    cbam_feature = tf.keras.activations.sigmoid(cbam_feature)\n",
        "\n",
        "    return Multiply()([input_feature, cbam_feature])\n",
        "from tensorflow.keras.layers import Conv2D, Concatenate, Activation\n",
        "\n",
        "def SpatialAttentionModule(input_feature):\n",
        "    kernel_size = 7\n",
        "\n",
        "    avg_pool = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(input_feature)\n",
        "    max_pool = tf.keras.layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(input_feature)\n",
        "    concat = Concatenate(axis=-1)([avg_pool, max_pool])\n",
        "    cbam_feature = Conv2D(filters=1,\n",
        "                          kernel_size=kernel_size,\n",
        "                          strides=1,\n",
        "                          padding='same',\n",
        "                          activation='sigmoid',\n",
        "                          kernel_initializer='he_normal',\n",
        "                          use_bias=False)(concat)\n",
        "\n",
        "    return Multiply()([input_feature, cbam_feature])\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense, Dropout, Concatenate\n",
        "from tensorflow.keras.applications import ResNet50, MobileNetV3Small\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class EdgeDetectionLayer(Layer):\n",
        "    def __init__(self):\n",
        "        super(EdgeDetectionLayer, self).__init__()\n",
        "        # Sobel filters\n",
        "        sobel_x = tf.constant([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=tf.float32)\n",
        "        sobel_y = tf.constant([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=tf.float32)\n",
        "        sobel_x = tf.reshape(sobel_x, [3, 3, 1, 1])\n",
        "        sobel_y = tf.reshape(sobel_y, [3, 3, 1, 1])\n",
        "        self.sobel_filters = tf.concat([sobel_x, sobel_y], axis=-1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        gray = tf.image.rgb_to_grayscale(inputs)\n",
        "        filtered = tf.nn.conv2d(gray, self.sobel_filters, strides=[1, 1, 1, 1], padding='SAME')\n",
        "        edges = tf.reduce_sum(tf.abs(filtered), axis=-1, keepdims=True)\n",
        "        return edges\n",
        "def build_cnn_with_attentionEdges(input_shape, num_classes, embed_dim=32, num_heads=2, num_transformer_layers=2, ff_dim=32):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Edge Detection Layer\n",
        "    edge_layer = EdgeDetectionLayer()\n",
        "    edges = edge_layer(inputs)\n",
        "\n",
        "    # Replace one channel of the input with the edge map\n",
        "    modified_input = tf.concat([inputs[..., :2], edges], axis=-1)\n",
        "\n",
        "    # DenseNet121 for Feature Extraction with modified input\n",
        "    densenet = DenseNet121(include_top=False, input_tensor=modified_input, weights='imagenet')\n",
        "    densenet.trainable = False\n",
        "\n",
        "\n",
        "    # Custom layers onto densenet\n",
        "    x = densenet.output\n",
        "    x = Conv2D(16, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = squeeze_excite_block(x)\n",
        "\n",
        "    x = Conv2D(16, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = squeeze_excite_block(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    # Flatten and apply Transformer blocks\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(embed_dim)(x)  # Projecting to transformer dimension\n",
        "\n",
        "    for _ in range(num_transformer_layers):\n",
        "        x = transformer_encoder(x, embed_dim, num_heads, ff_dim)\n",
        "\n",
        "    # Classifier head\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "\n",
        "    print(\"Shape before softmax:\", x.shape)  # Add this line for debugging\n",
        "\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_cnn_with_attentionandEdgesRes(input_shape, num_classes, embed_dim=32, num_heads=2, num_transformer_layers=2, ff_dim=32):\n",
        "\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Apply Edge Detection\n",
        "    edge_detector = EdgeDetectionLayer()\n",
        "    edges = edge_detector(inputs)\n",
        "\n",
        "    # Initialize DenseNet121\n",
        "    densenet = DenseNet121(include_top=False, input_tensor=inputs, weights='imagenet', pooling=None)\n",
        "    densenet.trainable = False\n",
        "\n",
        "    # Select an intermediate layer from DenseNet121\n",
        "    intermediate_layer = densenet.get_layer('conv5_block16_concat').output\n",
        "    intermediate_layer_resized = Resizing(inputs.shape[1], inputs.shape[2])(intermediate_layer)\n",
        "\n",
        "    # Concatenate edge features with intermediate DenseNet121 features\n",
        "    concatenated = Concatenate()([intermediate_layer_resized, edges])\n",
        "\n",
        "    # Additional custom layers\n",
        "    x = Conv2D(64, (3, 3), padding='same')(concatenated)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Transformer blocks (assuming transformer_encoder is defined)\n",
        "    x = Dense(embed_dim)(x)\n",
        "    for _ in range(num_transformer_layers):\n",
        "        x = transformer_encoder(x, embed_dim, num_heads, ff_dim)\n",
        "\n",
        "    # Classifier head\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "class laplacianGeometricHeatFlowLayer(Layer):\n",
        "    def __init__(self, iterations=10, diffusion_rate=0.1, **kwargs):\n",
        "        super(GeometricHeatFlowLayer, self).__init__(**kwargs)\n",
        "        self.iterations = iterations\n",
        "        self.diffusion_rate = diffusion_rate\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for _ in range(self.iterations):\n",
        "            x = self.apply_diffusion(x)\n",
        "        return x\n",
        "\n",
        "    def apply_diffusion(self, x):\n",
        "        # Laplacian kernel\n",
        "        laplacian_kernel = tf.constant([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], dtype=tf.float32)\n",
        "        laplacian_kernel = tf.reshape(laplacian_kernel, [3, 3, 1, 1])\n",
        "        laplacian_kernel = tf.tile(laplacian_kernel, [1, 1, tf.shape(x)[-1], 1])\n",
        "\n",
        "        # Apply Laplacian operator\n",
        "        laplacian = tf.nn.depthwise_conv2d(x, laplacian_kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "        # Update the image based on the diffusion equation\n",
        "        return x + self.diffusion_rate * laplacian\n",
        "\n",
        "class GeometricHeatFlowLayer(Layer):\n",
        "    def __init__(self, iterations=10, diffusion_rate=0.1, **kwargs):\n",
        "        super(GeometricHeatFlowLayer, self).__init__(**kwargs)\n",
        "        self.iterations = iterations\n",
        "        self.diffusion_rate = diffusion_rate\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for _ in range(self.iterations):\n",
        "            x = self.apply_diffusion(x)\n",
        "        return x\n",
        "\n",
        "    def apply_diffusion(self, x):\n",
        "        # Implement the diffusion process here\n",
        "        # This is a simplified example; you might need a more complex diffusion model\n",
        "        kernel = tf.constant([[0.05, 0.2, 0.05], [0.2, 0.2, 0.2], [0.05, 0.2, 0.05]], dtype=tf.float32)\n",
        "        kernel = tf.reshape(kernel, [3, 3, 1, 1])\n",
        "        kernel = tf.tile(kernel, [1, 1, tf.shape(x)[-1], 1])\n",
        "        return x + self.diffusion_rate * tf.nn.depthwise_conv2d(x, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "\n",
        "class AdvancedGeometricHeatFlowLayer(Layer):\n",
        "    def __init__(self, iterations=10, **kwargs):\n",
        "        super(AdvancedGeometricHeatFlowLayer, self).__init__(**kwargs)\n",
        "        self.iterations = iterations\n",
        "        self.diffusion_rate = 0.01\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for _ in range(self.iterations):\n",
        "            x = self.apply_anisotropic_diffusion(x)\n",
        "        return x\n",
        "\n",
        "    def apply_anisotropic_diffusion(self, x):\n",
        "        # Compute image gradients\n",
        "        dx, dy = self.compute_gradients(x)\n",
        "\n",
        "        # Compute edge-stopping function based on gradients\n",
        "        c = tf.exp(-tf.sqrt(tf.square(dx) + tf.square(dy)))\n",
        "\n",
        "        # Anisotropic diffusion\n",
        "        x = x + self.diffusion_rate * self.divergence(c * dx, c * dy)\n",
        "        return x\n",
        "\n",
        "    def compute_gradients(self, x):\n",
        "        # Sobel filters to approximate gradients\n",
        "        sobel_x = tf.constant([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=tf.float32, shape=[3, 3, 1, 1])\n",
        "        sobel_y = tf.constant([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=tf.float32, shape=[3, 3, 1, 1])\n",
        "\n",
        "        sobel_x = tf.tile(sobel_x, [1, 1, tf.shape(x)[-1], 1])\n",
        "        sobel_y = tf.tile(sobel_y, [1, 1, tf.shape(x)[-1], 1])\n",
        "\n",
        "        dx = tf.nn.depthwise_conv2d(x, sobel_x, strides=[1, 1, 1, 1], padding='SAME')\n",
        "        dy = tf.nn.depthwise_conv2d(x, sobel_y, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "        return dx, dy\n",
        "    def divergence(self, dx, dy):\n",
        "        num_channels = tf.shape(dx)[-1]\n",
        "\n",
        "        kernel_x = tf.constant([[-1, 1]], dtype=tf.float32)\n",
        "        kernel_x = tf.reshape(kernel_x, [2, 1, 1, 1])\n",
        "        kernel_x = tf.tile(kernel_x, [1, 1, num_channels, 1])\n",
        "\n",
        "        kernel_y = tf.constant([[-1], [1]], dtype=tf.float32)\n",
        "        kernel_y = tf.reshape(kernel_y, [1, 2, 1, 1])\n",
        "        kernel_y = tf.tile(kernel_y, [1, 1, num_channels, 1])\n",
        "\n",
        "        # Change padding from 'VALID' to 'SAME'\n",
        "        div_x = tf.nn.depthwise_conv2d(dx, kernel_x, strides=[1, 1, 1, 1], padding='SAME')\n",
        "        div_y = tf.nn.depthwise_conv2d(dy, kernel_y, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "        return div_x + div_y\n",
        "\n",
        "def build_cnn_with_attention_and_heat_flow(input_shape, num_classes, embed_dim=32, num_heads=2, num_transformer_layers=2, ff_dim=32):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Apply Geometric Heat Flow\n",
        "    heat_flow_layer = AdvancedGeometricHeatFlowLayer()\n",
        "    heat_flow = heat_flow_layer(inputs)\n",
        "\n",
        "    # Rest of the model remains the same...\n",
        "    # Initialize DenseNet121\n",
        "    densenet = DenseNet121(include_top=False, input_tensor=inputs, weights='imagenet', pooling=None)\n",
        "    densenet.trainable = False\n",
        "    # Select an intermediate layer from DenseNet121\n",
        "    intermediate_layer = densenet.get_layer('conv5_block16_concat').output\n",
        "    intermediate_layer_resized = Resizing(inputs.shape[1], inputs.shape[2])(intermediate_layer)\n",
        "\n",
        "    # Concatenate heat flow features with intermediate DenseNet121 features\n",
        "    concatenated = Concatenate()([intermediate_layer_resized, heat_flow])\n",
        "\n",
        "    # Additional custom layers\n",
        "    x = Conv2D(64, (3, 3), padding='same')(concatenated)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Transformer blocks (assuming transformer_encoder is defined)\n",
        "    x = Dense(embed_dim)(x)\n",
        "    for _ in range(num_transformer_layers):\n",
        "        x = transformer_encoder(x, embed_dim, num_heads, ff_dim)\n",
        "\n",
        "    # Classifier head\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "def train_individual_model(model, train_data, val_data, epochs=100):\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy', Precision(name='precision'), Recall(name='recall'), AUC(name='auc')])\n",
        "\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, verbose=1, restore_best_weights=True)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    history = model.fit(train_data, validation_data=val_data, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    # Using history to print training metrics\n",
        "    print(\"\\nTraining Metrics:\")\n",
        "    print(f\"Loss: {history.history['loss'][-1]}\")\n",
        "    print(f\"Accuracy: {history.history['accuracy'][-1]}\")\n",
        "    print(f\"Precision: {history.history['precision'][-1]}\")\n",
        "    print(f\"Recall: {history.history['recall'][-1]}\")\n",
        "    f1 = 2 * (history.history['precision'][-1] * history.history['recall'][-1]) / (history.history['precision'][-1] + history.history['recall'][-1])\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "    print(f\"AUC: {history.history['auc'][-1]}\")\n",
        "\n",
        "    # Using history to print validation metrics\n",
        "    print(\"\\nValidation Metrics:\")\n",
        "    print(f\"Loss: {history.history['val_loss'][-1]}\")\n",
        "    print(f\"Accuracy: {history.history['val_accuracy'][-1]}\")\n",
        "    print(f\"Precision: {history.history['val_precision'][-1]}\")\n",
        "    print(f\"Recall: {history.history['val_recall'][-1]}\")\n",
        "    val_f1 = 2 * (history.history['val_precision'][-1] * history.history['val_recall'][-1]) / (history.history['val_precision'][-1] + history.history['val_recall'][-1])\n",
        "    print(f\"Val F1 Score: {val_f1}\")\n",
        "    print(f\"Val AUC: {history.history['val_auc'][-1]}\")\n",
        "\n",
        "    return model\n",
        "vit_model = train_individual_model(build_model(input_shape,7), train_generator, validation_generator)\n"
      ]
    }
  ]
}